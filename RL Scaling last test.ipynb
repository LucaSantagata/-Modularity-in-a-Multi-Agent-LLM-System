{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d89fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Initialized (0-100). Best Arm Mean: 100.00\n",
      "Starting fresh experiment.\n",
      "Starting FINAL RL Experiment. Churn Target: ~0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions. Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 2/50 [15:44<6:18:45, 473.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions. Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 4/50 [34:50<6:52:11, 537.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions. Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                    | 16/50 [2:42:36<6:22:18, 674.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): 502 Server Error: Bad Gateway for url: https://api.mistral.ai/v1/chat/completions. Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▋                                                 | 18/50 [3:07:26<6:18:39, 709.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): HTTPSConnectionPool(host='api.mistral.ai', port=443): Read timed out. (read timeout=60). Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▍                     | 36/50 [7:00:54<2:56:47, 757.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Error (Attempt 1): 502 Server Error: Bad Gateway for url: https://api.mistral.ai/v1/chat/completions. Waiting 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 50/50 [10:11:08<00:00, 733.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saving final results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"lf3hE5UomEtiemAyKm8h5YJeHrSe5ltb\"\n",
    "MODEL = \"magistral-small-2509\"\n",
    "\n",
    "N_AGENTS = 30\n",
    "N_ARMS = 50\n",
    "N_ROUNDS = 50\n",
    "MOCK_MODE = False\n",
    "\n",
    "# RL Parameters\n",
    "RL_LEARNING_RATE = 0.5 \n",
    "\n",
    "# --- PATHS ---\n",
    "BASE_DIR = os.getcwd() \n",
    "CHECKPOINT_DF = os.path.join(BASE_DIR, \"real_experiment_df.pkl\")\n",
    "CHECKPOINT_LOG = os.path.join(BASE_DIR, \"real_message_log.pkl\")\n",
    "CHECKPOINT_WEIGHTS = os.path.join(BASE_DIR, \"real_weights_log.pkl\")\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def get_empty_structure():\n",
    "    return {'assigned_arms': [], 'chosen_arm': [], 'payoff': []}\n",
    "\n",
    "def initialize_experiment_log(num_agents, num_iterations):\n",
    "    data = []\n",
    "    for _ in range(num_iterations):\n",
    "        row_data = {f\"Agent_{i}\": get_empty_structure() for i in range(num_agents)}\n",
    "        row_data['Total_Payoff'] = 0.0\n",
    "        data.append(row_data)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def save_checkpoint(df, msg_log, weights_log):\n",
    "    tmp_df, tmp_msg, tmp_w = CHECKPOINT_DF + \".tmp\", CHECKPOINT_LOG + \".tmp\", CHECKPOINT_WEIGHTS + \".tmp\"\n",
    "    df.to_pickle(tmp_df)\n",
    "    with open(tmp_msg, \"wb\") as f: pickle.dump(msg_log, f)\n",
    "    with open(tmp_w, \"wb\") as f: pickle.dump(weights_log, f)\n",
    "    os.replace(tmp_df, CHECKPOINT_DF)\n",
    "    os.replace(tmp_msg, CHECKPOINT_LOG)\n",
    "    os.replace(tmp_w, CHECKPOINT_WEIGHTS)\n",
    "\n",
    "def load_checkpoint(n_agents, n_rounds):\n",
    "    if os.path.exists(CHECKPOINT_DF):\n",
    "        print(f\"Found checkpoint. Loading...\")\n",
    "        df = pd.read_pickle(CHECKPOINT_DF)\n",
    "        with open(CHECKPOINT_LOG, \"rb\") as f: msg_log = pickle.load(f)\n",
    "        with open(CHECKPOINT_WEIGHTS, \"rb\") as f: weights_log = pickle.load(f)\n",
    "        start_round = 0\n",
    "        for i in range(n_rounds):\n",
    "            if df.at[i, \"Agent_0\"]['chosen_arm']: start_round = i + 1\n",
    "            else: break\n",
    "        print(f\"Resuming from Round {start_round}...\")\n",
    "        return start_round, df, msg_log, weights_log\n",
    "    else:\n",
    "        print(\"Starting fresh experiment.\")\n",
    "        return 0, initialize_experiment_log(n_agents, n_rounds), [], []\n",
    "\n",
    "# --- ENVIRONMENT ---\n",
    "np.random.seed(42) \n",
    "_sorted_means = np.linspace(0, 100, N_ARMS)\n",
    "TRUE_ARM_MEANS = _sorted_means.copy()\n",
    "np.random.shuffle(TRUE_ARM_MEANS)\n",
    "print(f\"Environment Initialized (0-100). Best Arm Mean: {np.max(TRUE_ARM_MEANS):.2f}\")\n",
    "\n",
    "def get_arm_reward(arm_index):\n",
    "    mean = TRUE_ARM_MEANS[arm_index]\n",
    "    return round(np.clip(np.random.normal(loc=mean, scale=5.0), 0.0, 100.0), 2)\n",
    "\n",
    "# --- API ---\n",
    "def call_mistral(system_prompt, user_prompt):\n",
    "    if MOCK_MODE: return \"MOCK_RESPONSE\"\n",
    "    url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": MODEL, \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]}\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "            content = resp.json()['choices'][0]['message']['content']\n",
    "            if isinstance(content, list): \n",
    "                return \"\".join([c.get('text', '') for c in content if isinstance(c, dict) and c.get('type') == 'text']).strip()\n",
    "            return str(content).strip()\n",
    "        except Exception as e:\n",
    "            wait = 5 * (2 ** attempt)\n",
    "            print(f\"API Error (Attempt {attempt+1}): {e}. Waiting {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    return \"ERROR\"\n",
    "\n",
    "# --- CLASSES ---\n",
    "class Agent:\n",
    "    def __init__(self, agent_id, total_agents, total_arms, total_rounds):\n",
    "        self.agent_id = f\"Agent_{agent_id}\"\n",
    "        self.total_agents, self.total_arms, self.total_rounds = total_agents, total_arms, total_rounds\n",
    "        self.history, self.inbox = [], []\n",
    "\n",
    "    def get_system_prompt(self):\n",
    "        return f\"You are {self.agent_id} in a {self.total_agents}-agent bandit game. Rewards 0-100. Maximize team reward.\"\n",
    "\n",
    "    def _format_history(self):\n",
    "        return \"\\n\".join([f\"Round {r['round']}: Pulled Arm {r['arm']}, Reward: {r['payoff']:.2f}\" for r in self.history]) if self.history else \"No history.\"\n",
    "\n",
    "    def generate_message(self, current_round, assigned_arms, assignment_map):\n",
    "        user_prompt = (f\"--- ROUND {current_round} ---\\nMy Arms: {assigned_arms}\\nMap: {assignment_map}\\nHistory:\\n{self._format_history()}\\n\"\n",
    "                       \"Task: Message ONE agent. Keep it short.\\nFormat: 'TO: Agent_X | MSG: <content>'\")\n",
    "        resp = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        if MOCK_MODE: return f\"Agent_{random.randint(0, self.total_agents-1)}\", \"Mock\"\n",
    "        match = re.search(r\"TO:\\s*(Agent_\\d+).*?MSG:\\s*(.*)\", resp, re.DOTALL | re.IGNORECASE)\n",
    "        return (match.group(1).strip(), match.group(2).strip()) if match else (None, None)\n",
    "\n",
    "    def receive_message(self, sender, content):\n",
    "        self.inbox.append(f\"From {sender}: {content}\")\n",
    "\n",
    "    def make_choice(self, assigned_arms):\n",
    "        # --- FIXED SYNTAX ERROR HERE ---\n",
    "        # We perform the string join OUTSIDE the f-string to prevent backslash issues\n",
    "        inbox_str = '\\n'.join(self.inbox) if self.inbox else 'None'\n",
    "        \n",
    "        user_prompt = (f\"Msgs:\\n{inbox_str}\\n\\nPick arm from {assigned_arms}. Return integer ONLY.\")\n",
    "        \n",
    "        resp = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        if MOCK_MODE: return random.choice(assigned_arms)\n",
    "        nums = re.findall(r'\\d+', resp)\n",
    "        return int(nums[0]) if nums and int(nums[0]) in assigned_arms else random.choice(assigned_arms)\n",
    "\n",
    "    def update_history(self, r, arm, payoff):\n",
    "        self.history.append({'round': r, 'arm': arm, 'payoff': payoff})\n",
    "\n",
    "class SharpRLManager:\n",
    "    def __init__(self, num_arms, num_agents, learning_rate):\n",
    "        self.num_arms, self.num_agents, self.lr = num_arms, num_agents, learning_rate\n",
    "        self.weights = np.zeros((num_agents, num_arms))\n",
    "\n",
    "    def assign_arms(self):\n",
    "        assignment = {f\"Agent_{i}\": [] for i in range(self.num_agents)}\n",
    "        probs = softmax(self.weights, axis=0)\n",
    "        indices = list(range(self.num_agents))\n",
    "        counts = np.zeros(self.num_agents, dtype=int)\n",
    "        \n",
    "        for arm in range(self.num_arms):\n",
    "            chosen = np.random.choice(indices, p=probs[:, arm])\n",
    "            assignment[f\"Agent_{chosen}\"].append(arm)\n",
    "            counts[chosen] += 1\n",
    "            \n",
    "        empty = [i for i, c in enumerate(counts) if c == 0]\n",
    "        if empty:\n",
    "            wealthy = [i for i, c in enumerate(counts) if c > 1]\n",
    "            random.shuffle(empty)\n",
    "            for poor in empty:\n",
    "                if not wealthy: break\n",
    "                donor = wealthy[0]\n",
    "                steal = assignment[f\"Agent_{donor}\"].pop()\n",
    "                counts[donor] -= 1\n",
    "                assignment[f\"Agent_{poor}\"].append(steal)\n",
    "                counts[poor] += 1\n",
    "                if counts[donor] <= 1: wealthy.pop(0)\n",
    "        return assignment\n",
    "\n",
    "    def update_weights(self, agent_id, arm_idx, reward):\n",
    "        idx = int(agent_id.split(\"_\")[1])\n",
    "        # Sharp scaling /5.0\n",
    "        self.weights[idx, arm_idx] += self.lr * (reward / 5.0)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    start, df, msg_log, w_log = load_checkpoint(N_AGENTS, N_ROUNDS)\n",
    "    agents = [Agent(i, N_AGENTS, N_ARMS, N_ROUNDS) for i in range(N_AGENTS)]\n",
    "    manager = SharpRLManager(N_ARMS, N_AGENTS, RL_LEARNING_RATE)\n",
    "    \n",
    "    if start > 0:\n",
    "        print(\"Restoring state...\")\n",
    "        for r in range(start):\n",
    "            for a in agents:\n",
    "                rec = df.at[r, a.agent_id]\n",
    "                if rec['chosen_arm']: a.update_history(r, rec['chosen_arm'][0], rec['payoff'][0])\n",
    "        if w_log: manager.weights = w_log[-1].copy()\n",
    "\n",
    "    print(f\"Starting FINAL RL Experiment. Churn Target: ~0.18\")\n",
    "    for t in tqdm(range(start, N_ROUNDS)):\n",
    "        assigns = manager.assign_arms()\n",
    "        \n",
    "        # Phase 1\n",
    "        msgs = []\n",
    "        for a in agents:\n",
    "            tid, c = a.generate_message(t, assigns[a.agent_id], assigns)\n",
    "            if tid and tid in assigns and tid != a.agent_id:\n",
    "                rec = {'iteration': t, 'sender': a.agent_id, 'receiver': tid, 'message': c}\n",
    "                msgs.append(rec)\n",
    "                msg_log.append(rec)\n",
    "        agent_map = {a.agent_id: a for a in agents}\n",
    "        for m in msgs: agent_map[m['receiver']].receive_message(m['sender'], m['message'])\n",
    "        \n",
    "        # Phase 2\n",
    "        rewards = []\n",
    "        for a in agents:\n",
    "            my_arms = assigns[a.agent_id]\n",
    "            ch = a.make_choice(my_arms)\n",
    "            pay = get_arm_reward(ch)\n",
    "            \n",
    "            a.update_history(t, ch, pay)\n",
    "            manager.update_weights(a.agent_id, ch, pay)\n",
    "            \n",
    "            df.at[t, a.agent_id] = {'assigned_arms': list(my_arms), 'chosen_arm': [ch], 'payoff': [pay]}\n",
    "            rewards.append(pay)\n",
    "            \n",
    "        df.at[t, 'Total_Payoff'] = np.average(rewards)\n",
    "        w_log.append(manager.weights.copy())\n",
    "        save_checkpoint(df, msg_log, w_log)\n",
    "        \n",
    "    print(\"Done. Saving final results...\")\n",
    "    df.to_csv(\"final_sharp_rl_results.csv\")\n",
    "    pd.DataFrame(msg_log).to_csv(\"final_sharp_messages.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
