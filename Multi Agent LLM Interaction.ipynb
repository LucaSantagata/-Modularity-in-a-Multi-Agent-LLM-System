{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e59be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Mock Mode is: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from mistralai import Mistral\n",
    "from tqdm import tqdm # <--- NEW IMPORT\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"4aSIsAS2QW3dzgQuckWLz4hC7bN9ZBfw\"  # <--- Paste your Key here\n",
    "MODEL = \"magistral-small-2509\" # Or \"mistral-small-2509\"\n",
    "\n",
    "# Experiment Parameters\n",
    "N_AGENTS = 2\n",
    "N_ARMS = 10\n",
    "N_ROUNDS = 1\n",
    "ARMS_PER_AGENT = 2  # How many arms each agent gets per round\n",
    "\n",
    "# Set this to False to run the REAL experiment (costs money/credits)\n",
    "# Set this to True to test the code logic quickly (free)\n",
    "MOCK_MODE = False \n",
    "\n",
    "# Initialize Mistral Client\n",
    "if not MOCK_MODE:\n",
    "    client = Mistral(api_key=API_KEY)\n",
    "else:\n",
    "    client = None\n",
    "\n",
    "print(f\"Setup Complete. Mock Mode is: {MOCK_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3c5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. DEFINE THE ENVIRONMENT (ARMS) ---\n",
    "np.random.seed(42) \n",
    "TRUE_ARM_MEANS = np.clip(np.random.normal(loc=0.5, scale=0.15, size=N_ARMS), 0.0, 1.0)\n",
    "\n",
    "def get_arm_reward(arm_index):\n",
    "    mean = TRUE_ARM_MEANS[arm_index]\n",
    "    reward = np.random.normal(loc=mean, scale=0.05)\n",
    "    return round(reward, 4)\n",
    "\n",
    "# --- 2. ROBUST MISTRAL API WRAPPER (With Rate Limit Handling) ---\n",
    "def call_mistral(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Handles the API call with a Retry Loop and Exponential Backoff.\n",
    "    This prevents the code from crashing if Mistral says 'Too Many Requests'.\n",
    "    \"\"\"\n",
    "    if MOCK_MODE:\n",
    "        return \"MOCK_RESPONSE\"\n",
    "\n",
    "    max_retries = 5\n",
    "    base_wait = 5 # Start waiting 5 seconds\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Attempt the API Call\n",
    "            response = client.chat.complete(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Parse Response\n",
    "            msg = response.choices[0].message\n",
    "            content = msg.content\n",
    "\n",
    "            if isinstance(content, str):\n",
    "                return content\n",
    "            else:\n",
    "                visible_text = []\n",
    "                for chunk in content:\n",
    "                    if getattr(chunk, \"type\", None) == \"text\":\n",
    "                        visible_text.append(getattr(chunk, \"text\", \"\"))\n",
    "                return \"\".join(visible_text).strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            # Check if it's a Rate Limit (usually contains \"429\" or \"Rate limit\")\n",
    "            error_msg = str(e).lower()\n",
    "            is_rate_limit = \"429\" in error_msg or \"rate limit\" in error_msg\n",
    "            \n",
    "            wait_time = base_wait * (2 ** attempt) # 5s, 10s, 20s, 40s...\n",
    "            \n",
    "            print(f\"\\n[API Warning] Attempt {attempt+1}/{max_retries} failed.\")\n",
    "            print(f\"Error: {e}\")\n",
    "            \n",
    "            if is_rate_limit:\n",
    "                print(f\"Rate Limit Hit. Sleeping for {wait_time} seconds...\")\n",
    "            else:\n",
    "                print(f\"Generic Error. Retrying in {wait_time} seconds...\")\n",
    "                \n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    # If we exit the loop, we failed 5 times in a row.\n",
    "    print(\"\\n[CRITICAL FAIL] Max retries exceeded. Returning fallback.\")\n",
    "    return \"ERROR: MAX RETRIES EXCEEDED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8e6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structures initialized.\n"
     ]
    }
   ],
   "source": [
    "def get_empty_structure():\n",
    "    \"\"\"Helper to create unique dictionary objects for the DataFrame.\"\"\"\n",
    "    return {\n",
    "        'assigned_arms': [], \n",
    "        'chosen_arm': [], \n",
    "        'payoff': []\n",
    "    }\n",
    "\n",
    "def initialize_experiment_log(num_agents, num_iterations):\n",
    "    \"\"\"Creates the main DataFrame.\"\"\"\n",
    "    data = []\n",
    "    for _ in range(num_iterations):\n",
    "        row_data = {}\n",
    "        for i in range(num_agents):\n",
    "            row_data[f\"Agent_{i}\"] = get_empty_structure()\n",
    "        row_data['Total_Payoff'] = 0.0\n",
    "        data.append(row_data)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def initialize_message_log():\n",
    "    \"\"\"Creates the list to store message history.\"\"\"\n",
    "    return []\n",
    "\n",
    "# Create the structures\n",
    "experiment_df = initialize_experiment_log(N_AGENTS, N_ROUNDS)\n",
    "message_log = initialize_message_log()\n",
    "\n",
    "print(\"Data structures initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5b4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, agent_id, total_agents, total_arms, total_rounds):\n",
    "        self.agent_id = f\"Agent_{agent_id}\"\n",
    "        self.id_num = agent_id\n",
    "        self.total_agents = total_agents\n",
    "        self.total_arms = total_arms\n",
    "        self.total_rounds = total_rounds\n",
    "        \n",
    "        # Memory\n",
    "        self.history = []  # List of dicts: {'round', 'arm', 'payoff'}\n",
    "        self.inbox = []    # List of messages received in current round\n",
    "        \n",
    "    def get_system_prompt(self):\n",
    "        return (\n",
    "            f\"You are {self.agent_id}, participating in a cooperative Multi-Armed Bandit game. \"\n",
    "            f\"There are {self.total_agents} agents, {self.total_arms} total arms, \"\n",
    "            f\"and the game lasts {self.total_rounds} rounds. \"\n",
    "            \"Your goal is to maximize the team's average reward.\"\n",
    "        )\n",
    "\n",
    "    def _format_history(self):\n",
    "        \"\"\"\n",
    "        Format: Round X: Pulled Arm Y, Reward: Z\n",
    "        UPDATED: Returns ALL history, not just the last 5.\n",
    "        \"\"\"\n",
    "        # recent = self.history[-5:] <--- OLD CODE (Deleted)\n",
    "        recent = self.history      # <--- NEW CODE (Keep everything)\n",
    "        \n",
    "        if not recent:\n",
    "            return \"No history yet.\"\n",
    "            \n",
    "        formatted = []\n",
    "        for record in recent:\n",
    "            line = (f\"Round {record['round']}: Pulled Arm {record['arm']}, \"\n",
    "                    f\"Reward: {record['payoff']:.4f}\")\n",
    "            formatted.append(line)\n",
    "        return \"\\n\".join(formatted)\n",
    "\n",
    "    # --- PHASE 1: DECIDE WHO TO MESSAGE ---\n",
    "    def generate_message(self, current_round, assigned_arms, assignment_map):\n",
    "        \n",
    "        hist_str = self._format_history()\n",
    "        \n",
    "        user_prompt = (\n",
    "            f\"--- ROUND {current_round} ---\\n\"\n",
    "            f\"My Assigned Arms: {assigned_arms}\\n\"\n",
    "            f\"All Agents' Assignments: {assignment_map}\\n\"\n",
    "            f\"My Recent History:\\n{hist_str}\\n\\n\"\n",
    "            \"Task: Based on your history and the map, choose one agent to message. \"\n",
    "            \"Tell them something useful.\\n\"\n",
    "            \"Response Format: 'TO: Agent_X | MSG: <content>'\\n\"\n",
    "            \"Example: 'TO: Agent_4 | MSG: I tried arm 2 and got 0.8 reward.'\"\n",
    "        )\n",
    "        \n",
    "        # Get raw text from LLM\n",
    "        response_text = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        \n",
    "        # Parse the response\n",
    "        target_agent = None\n",
    "        message_content = \"No message\"\n",
    "        \n",
    "        if MOCK_MODE:\n",
    "            # Random logic for testing\n",
    "            target_id = random.randint(0, self.total_agents - 1)\n",
    "            target_agent = f\"Agent_{target_id}\"\n",
    "            message_content = f\"Hello from {self.agent_id}\"\n",
    "        else:\n",
    "            # Regex to find \"TO: Agent_X\" and \"MSG: ...\"\n",
    "            match = re.search(r\"TO:\\s*(Agent_\\d+).*?MSG:\\s*(.*)\", response_text, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                target_agent = match.group(1).strip()\n",
    "                message_content = match.group(2).strip()\n",
    "            else:\n",
    "                # Fallback if format is wrong\n",
    "                print(f\"Format Warning {self.agent_id}: {response_text[:50]}...\")\n",
    "        \n",
    "        return target_agent, message_content\n",
    "\n",
    "    # --- INTERMEDIATE: RECEIVE ---\n",
    "    def receive_message(self, sender_id, content):\n",
    "        self.inbox.append(f\"From {sender_id}: {content}\")\n",
    "\n",
    "    # --- PHASE 2: DECIDE WHICH ARM TO PULL ---\n",
    "    def make_choice(self, assigned_arms):\n",
    "        \n",
    "        inbox_text = \"\\n\".join(self.inbox) if self.inbox else \"No messages received.\"\n",
    "        \n",
    "        user_prompt = (\n",
    "            f\"You have received the following messages from other agents:\\n{inbox_text}\\n\\n\"\n",
    "            f\"Considering your history and this new advice, which arm will you pull from {assigned_arms}?\\n\"\n",
    "            \"Return ONLY the integer of the arm.\"\n",
    "        )\n",
    "        \n",
    "        # We include the system prompt again to ensure persona is kept\n",
    "        response_text = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        \n",
    "        choice = None\n",
    "        \n",
    "        if MOCK_MODE:\n",
    "            choice = random.choice(assigned_arms)\n",
    "        else:\n",
    "            # Extract first number found in response\n",
    "            numbers = re.findall(r'\\d+', response_text)\n",
    "            if numbers:\n",
    "                choice = int(numbers[0])\n",
    "                # Validation: Ensure choice is in assigned_arms\n",
    "                if choice not in assigned_arms:\n",
    "                    choice = random.choice(assigned_arms) # Fallback\n",
    "            else:\n",
    "                choice = random.choice(assigned_arms) # Fallback\n",
    "                \n",
    "        # Clear inbox for next round\n",
    "        self.inbox = []\n",
    "        \n",
    "        return choice\n",
    "\n",
    "    def update_history(self, round_num, arm, payoff):\n",
    "        self.history.append({'round': round_num, 'arm': arm, 'payoff': payoff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e0dfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomManager:\n",
    "    def __init__(self, num_arms, num_agents, arms_per_agent):\n",
    "        self.num_arms = num_arms\n",
    "        self.num_agents = num_agents\n",
    "        self.arms_per_agent = arms_per_agent\n",
    "        self.all_arms = list(range(num_arms))\n",
    "\n",
    "    def assign_arms(self):\n",
    "        \"\"\"\n",
    "        Assigns arms ensuring full coverage while completely eliminating\n",
    "        agent bias (e.g., Agent 0 always getting more arms).\n",
    "        \"\"\"\n",
    "        assignment = {f\"Agent_{i}\": [] for i in range(self.num_agents)}\n",
    "        \n",
    "        # --- STEP 1: RANDOMIZE EVERYTHING ---\n",
    "        \n",
    "        # A. Shuffle the \"Deck\" of Arms\n",
    "        deck_of_arms = self.all_arms[:]\n",
    "        random.shuffle(deck_of_arms)\n",
    "        \n",
    "        # B. Shuffle the \"Seating Order\" of Agents\n",
    "        # This ensures the 'remainder' arms don't always fall to Agent 0-3\n",
    "        agent_order = list(range(self.num_agents))\n",
    "        random.shuffle(agent_order)\n",
    "        \n",
    "        # --- STEP 2: DEAL FOR COVERAGE ---\n",
    "        # Deal the arms one by one to the agents in their random order\n",
    "        for i, arm in enumerate(deck_of_arms):\n",
    "            # Use modulo on the loop counter 'i', NOT the arm ID\n",
    "            # This ensures we cycle through the agents 0, 1, 2... evenly\n",
    "            target_agent_idx = agent_order[i % self.num_agents]\n",
    "            assignment[f\"Agent_{target_agent_idx}\"].append(arm)\n",
    "            \n",
    "        # --- STEP 3: FILL QUOTAS (TOP UP) ---\n",
    "        # Now we ensure everyone reaches 'arms_per_agent'\n",
    "        for i in range(self.num_agents):\n",
    "            agent_key = f\"Agent_{i}\"\n",
    "            current_count = len(assignment[agent_key])\n",
    "            needed = self.arms_per_agent - current_count\n",
    "            \n",
    "            if needed > 0:\n",
    "                # Pick random extra arms that this agent doesn't have yet\n",
    "                available = [x for x in self.all_arms if x not in assignment[agent_key]]\n",
    "                \n",
    "                # Safety check: if needed > available (rare edge case), take all available\n",
    "                take_count = min(len(available), needed)\n",
    "                \n",
    "                if take_count > 0:\n",
    "                    new_picks = random.sample(available, take_count)\n",
    "                    assignment[agent_key].extend(new_picks)\n",
    "        \n",
    "        return assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a6d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and load checkpoint functions\n",
    "\n",
    "CHECKPOINT_DF = \"checkpoint_experiment_df.pkl\"\n",
    "CHECKPOINT_LOG = \"checkpoint_message_log.pkl\"\n",
    "\n",
    "def save_checkpoint(df, msg_log):\n",
    "    df.to_pickle(CHECKPOINT_DF)\n",
    "    with open(CHECKPOINT_LOG, \"wb\") as f:\n",
    "        pickle.dump(msg_log, f)\n",
    "\n",
    "def load_checkpoint(n_agents, n_rounds):\n",
    "    if os.path.exists(CHECKPOINT_DF) and os.path.exists(CHECKPOINT_LOG):\n",
    "        print(\"Found checkpoint files. Loading previous state...\")\n",
    "        df = pd.read_pickle(CHECKPOINT_DF)\n",
    "        with open(CHECKPOINT_LOG, \"rb\") as f:\n",
    "            msg_log = pickle.load(f)\n",
    "            \n",
    "        start_round = 0\n",
    "        for i in range(n_rounds):\n",
    "            # Check if Agent_0 has data for this round\n",
    "            if df.at[i, f\"Agent_0\"]['chosen_arm']: \n",
    "                start_round = i + 1\n",
    "            else:\n",
    "                break\n",
    "        print(f\"Resuming from Round {start_round}...\")\n",
    "        return start_round, df, msg_log\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting fresh.\")\n",
    "        df = initialize_experiment_log(n_agents, n_rounds)\n",
    "        msg_log = initialize_message_log()\n",
    "        return 0, df, msg_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590f1673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint files. Loading previous state...\n",
      "Resuming from Round 1...\n",
      "Restoring agent memories from dataframe...\n",
      "Starting Simulation from Round 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation Progress: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- SETUP & RESUME LOGIC ---\n",
    "start_round, experiment_df, message_log = load_checkpoint(N_AGENTS, N_ROUNDS)\n",
    "\n",
    "# Re-initialize Agents and Manager\n",
    "agents = [Agent(i, N_AGENTS, N_ARMS, N_ROUNDS) for i in range(N_AGENTS)]\n",
    "manager = RandomManager(N_ARMS, N_AGENTS, ARMS_PER_AGENT)\n",
    "\n",
    "# RESTORE MEMORY (If resuming)\n",
    "if start_round > 0:\n",
    "    print(\"Restoring agent memories from dataframe...\")\n",
    "    for r in range(start_round):\n",
    "        for agent in agents:\n",
    "            record = experiment_df.at[r, agent.agent_id]\n",
    "            if record['chosen_arm']:\n",
    "                agent.update_history(r, record['chosen_arm'][0], record['payoff'][0])\n",
    "\n",
    "print(f\"Starting Simulation from Round {start_round} of {N_ROUNDS}\")\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for t in tqdm(range(start_round, N_ROUNDS), desc=\"Simulation Progress\"):\n",
    "    \n",
    "    # 1. Manager assigns arms\n",
    "    assignments = manager.assign_arms()\n",
    "    \n",
    "    # 2. Phase 1: Communication\n",
    "    messages_this_round = []\n",
    "    for agent in agents:\n",
    "        my_arms = assignments[agent.agent_id]\n",
    "        target_id, msg_content = agent.generate_message(t, my_arms, assignments)\n",
    "        \n",
    "        if target_id and target_id in assignments and target_id != agent.agent_id:\n",
    "            msg_record = {\n",
    "                'iteration': t, \n",
    "                'sender': agent.agent_id, \n",
    "                'receiver': target_id, \n",
    "                'message': msg_content\n",
    "            }\n",
    "            messages_this_round.append(msg_record)\n",
    "            message_log.append(msg_record)\n",
    "    \n",
    "    # 3. Deliver Messages\n",
    "    agent_map = {a.agent_id: a for a in agents}\n",
    "    for msg in messages_this_round:\n",
    "        receiver_obj = agent_map[msg['receiver']]\n",
    "        receiver_obj.receive_message(msg['sender'], msg['message'])\n",
    "        \n",
    "    # 4. Phase 2: Action\n",
    "    round_payoffs = []\n",
    "    for agent in agents:\n",
    "        my_arms = assignments[agent.agent_id]\n",
    "        chosen_arm = agent.make_choice(my_arms)\n",
    "        payoff = get_arm_reward(chosen_arm)\n",
    "        \n",
    "        agent.update_history(t, chosen_arm, payoff)\n",
    "        \n",
    "        experiment_df.at[t, agent.agent_id] = {\n",
    "            'assigned_arms': list(my_arms),\n",
    "            'chosen_arm': [chosen_arm],\n",
    "            'payoff': [payoff]\n",
    "        }\n",
    "        round_payoffs.append(payoff)\n",
    "        \n",
    "    # 5. Update Stats & SAVE CHECKPOINT\n",
    "    total_score = np.average(round_payoffs)\n",
    "    experiment_df.at[t, 'Total_Payoff'] = total_score\n",
    "    \n",
    "    # Save progress to disk immediately\n",
    "    save_checkpoint(experiment_df, message_log)\n",
    "    \n",
    "    tqdm.write(f\"Round {t} | Avg Payoff: {total_score:.4f} | Msgs Sent: {len(messages_this_round)}\")\n",
    "\n",
    "print(\"\\nExperiment Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cfcbb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Data (First 5 rounds):\n",
      "                                                                     Agent_0  \\\n",
      "0  {'assigned_arms': [1, 9, 5, 2, 3], 'chosen_arm': [1], 'payoff': [0.4561]}   \n",
      "\n",
      "                                                                     Agent_1  \\\n",
      "0  {'assigned_arms': [0, 4, 8, 7, 6], 'chosen_arm': [0], 'payoff': [0.5512]}   \n",
      "\n",
      "   Total_Payoff  \n",
      "0       0.50365  \n",
      "\n",
      "Message Log:\n",
      "{'iteration': 0, 'sender': 'Agent_0', 'receiver': 'Agent_1', 'message': \"Let's share the arm number and reward after each pull to help maximize the team's average reward.\"}\n",
      "{'iteration': 0, 'sender': 'Agent_1', 'receiver': 'Agent_0', 'message': \"Iâ€™m assigned arms [0,4,6,7,8]. Let's coordinate to avoid overlapping arms.\"}\n",
      "\n",
      "Files saved: 'experiment_results.csv' and 'message_log.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. View the Main DataFrame\n",
    "print(\"Experiment Data (First 5 rounds):\")\n",
    "print(experiment_df.head())\n",
    "\n",
    "# 2. View the Message Log (First 5 messages)\n",
    "print(\"\\nMessage Log:\")\n",
    "for msg in message_log[:]:\n",
    "    print(msg)\n",
    "\n",
    "# 3. Save to CSV for your Network Science Students\n",
    "experiment_df.to_csv(\"experiment_results.csv\")\n",
    "pd.DataFrame(message_log).to_csv(\"message_log.csv\")\n",
    "print(\"\\nFiles saved: 'experiment_results.csv' and 'message_log.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "679f73c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent_0</th>\n",
       "      <th>Agent_1</th>\n",
       "      <th>Total_Payoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'assigned_arms': [1, 9, 5, 2, 3], 'chosen_arm': [1], 'payoff': [0.4561]}</td>\n",
       "      <td>{'assigned_arms': [0, 4, 8, 7, 6], 'chosen_arm': [0], 'payoff': [0.5512]}</td>\n",
       "      <td>0.50365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Agent_0  \\\n",
       "0  {'assigned_arms': [1, 9, 5, 2, 3], 'chosen_arm': [1], 'payoff': [0.4561]}   \n",
       "\n",
       "                                                                     Agent_1  \\\n",
       "0  {'assigned_arms': [0, 4, 8, 7, 6], 'chosen_arm': [0], 'payoff': [0.5512]}   \n",
       "\n",
       "   Total_Payoff  \n",
       "0       0.50365  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18eeac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)           # Max righe mostrate (default: 60)\n",
    "pd.set_option('display.max_columns', None)        # Max colonne mostrate (default: 20)\n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12bdec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent_0</th>\n",
       "      <th>Agent_1</th>\n",
       "      <th>Total_Payoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'assigned_arms': [1, 9, 5, 2, 3], 'chosen_arm': [1], 'payoff': [0.4561]}</td>\n",
       "      <td>{'assigned_arms': [0, 4, 8, 7, 6], 'chosen_arm': [0], 'payoff': [0.5512]}</td>\n",
       "      <td>0.50365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Agent_0  \\\n",
       "0  {'assigned_arms': [1, 9, 5, 2, 3], 'chosen_arm': [1], 'payoff': [0.4561]}   \n",
       "\n",
       "                                                                     Agent_1  \\\n",
       "0  {'assigned_arms': [0, 4, 8, 7, 6], 'chosen_arm': [0], 'payoff': [0.5512]}   \n",
       "\n",
       "   Total_Payoff  \n",
       "0       0.50365  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
