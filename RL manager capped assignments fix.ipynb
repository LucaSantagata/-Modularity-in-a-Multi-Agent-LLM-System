{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacb79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Initialized (0-100). Best Arm Mean: 100.00\n",
      "No checkpoint found. Starting fresh experiment.\n",
      "Starting RL Simulation. Alpha=0.5, Temp=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:   0%|                                                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:   5%|███▎                                                               | 1/20 [08:45<2:46:19, 525.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:  10%|██████▋                                                            | 2/20 [16:31<2:27:06, 490.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:  15%|██████████                                                         | 3/20 [23:59<2:13:31, 471.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress:  40%|██████████████████████████                                       | 8/20 [1:07:53<1:47:24, 537.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress:  50%|████████████████████████████████                                | 10/20 [1:27:29<1:33:52, 563.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress:  60%|██████████████████████████████████████▍                         | 12/20 [1:45:27<1:13:30, 551.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress:  70%|██████████████████████████████████████████████▏                   | 14/20 [2:04:08<55:46, 557.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:  75%|█████████████████████████████████████████████████▌                | 15/20 [2:13:04<45:55, 551.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress:  90%|███████████████████████████████████████████████████████████▍      | 18/20 [2:40:22<18:17, 548.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "RL Progress:  95%|██████████████████████████████████████████████████████████████▋   | 19/20 [2:48:43<08:54, 534.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n",
      "\n",
      "[API Warning] Attempt 1 failed: API error occurred: Status 429. Body: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}\n",
      "Rate Limit Hit. Sleeping 5s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Progress: 100%|██████████████████████████████████████████████████████████████████| 20/20 [2:57:41<00:00, 533.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Exporting...\n",
      "All files saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from mistralai import Mistral\n",
    "from scipy.special import softmax\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"4aSIsAS2QW3dzgQuckWLz4hC7bN9ZBfw\" \n",
    "MODEL = \"magistral-small-2509\"\n",
    "\n",
    "# Experiment Parameters\n",
    "N_AGENTS = 30\n",
    "N_ARMS = 50\n",
    "N_ROUNDS = 20\n",
    "MOCK_MODE = False\n",
    "\n",
    "# RL Parameters\n",
    "RL_LEARNING_RATE = 0.5\n",
    "RL_TEMPERATURE = .3\n",
    "\n",
    "# --- CLUSTER PATHS ---\n",
    "BASE_DIR = os.getcwd() \n",
    "CHECKPOINT_DF = os.path.join(BASE_DIR, \"checkpoint_experiment_df.pkl\")\n",
    "CHECKPOINT_LOG = os.path.join(BASE_DIR, \"checkpoint_message_log.pkl\")\n",
    "CHECKPOINT_WEIGHTS = os.path.join(BASE_DIR, \"checkpoint_weights_log.pkl\") # <--- NEW FILE\n",
    "\n",
    "# Initialize Client\n",
    "if not MOCK_MODE:\n",
    "    client = Mistral(api_key=API_KEY)\n",
    "else:\n",
    "    client = None\n",
    "\n",
    "# --- 1. HELPER FUNCTIONS ---\n",
    "def get_empty_structure():\n",
    "    return {'assigned_arms': [], 'chosen_arm': [], 'payoff': []}\n",
    "\n",
    "def initialize_experiment_log(num_agents, num_iterations):\n",
    "    data = []\n",
    "    for _ in range(num_iterations):\n",
    "        row_data = {f\"Agent_{i}\": get_empty_structure() for i in range(num_agents)}\n",
    "        row_data['Total_Payoff'] = 0.0\n",
    "        data.append(row_data)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def initialize_message_log():\n",
    "    return []\n",
    "\n",
    "def initialize_weights_log():\n",
    "    return []\n",
    "\n",
    "# --- 2. CLUSTER-SAFE CHECKPOINTING ---\n",
    "def save_checkpoint(df, msg_log, weights_log):\n",
    "    \"\"\"\n",
    "    Saves DF, Messages, AND the Weight Matrix History.\n",
    "    Atomic writes to prevent corruption.\n",
    "    \"\"\"\n",
    "    # Define Temps\n",
    "    tmp_df = CHECKPOINT_DF + \".tmp\"\n",
    "    tmp_msg = CHECKPOINT_LOG + \".tmp\"\n",
    "    tmp_w = CHECKPOINT_WEIGHTS + \".tmp\"\n",
    "    \n",
    "    # Write Temps\n",
    "    df.to_pickle(tmp_df)\n",
    "    with open(tmp_msg, \"wb\") as f: pickle.dump(msg_log, f)\n",
    "    with open(tmp_w, \"wb\") as f: pickle.dump(weights_log, f)\n",
    "        \n",
    "    # Atomic Rename\n",
    "    os.replace(tmp_df, CHECKPOINT_DF)\n",
    "    os.replace(tmp_msg, CHECKPOINT_LOG)\n",
    "    os.replace(tmp_w, CHECKPOINT_WEIGHTS)\n",
    "\n",
    "def load_checkpoint(n_agents, n_rounds):\n",
    "    if os.path.exists(CHECKPOINT_DF) and os.path.exists(CHECKPOINT_LOG) and os.path.exists(CHECKPOINT_WEIGHTS):\n",
    "        print(f\"Found checkpoint. Loading...\")\n",
    "        df = pd.read_pickle(CHECKPOINT_DF)\n",
    "        with open(CHECKPOINT_LOG, \"rb\") as f: msg_log = pickle.load(f)\n",
    "        with open(CHECKPOINT_WEIGHTS, \"rb\") as f: weights_log = pickle.load(f)\n",
    "            \n",
    "        start_round = 0\n",
    "        for i in range(n_rounds):\n",
    "            if df.at[i, \"Agent_0\"]['chosen_arm']: \n",
    "                start_round = i + 1\n",
    "            else:\n",
    "                break\n",
    "        print(f\"Resuming experiment from Round {start_round}...\")\n",
    "        return start_round, df, msg_log, weights_log\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting fresh experiment.\")\n",
    "        df = initialize_experiment_log(n_agents, n_rounds)\n",
    "        msg_log = initialize_message_log()\n",
    "        weights_log = initialize_weights_log()\n",
    "        return 0, df, msg_log, weights_log\n",
    "\n",
    "# --- 3. ENVIRONMENT & API ---\n",
    "np.random.seed(42) \n",
    "\n",
    "# Generate Evenly Spaced Means (0-100) & Shuffle\n",
    "_sorted_means = np.linspace(0, 100, N_ARMS)\n",
    "TRUE_ARM_MEANS = _sorted_means.copy()\n",
    "np.random.shuffle(TRUE_ARM_MEANS)\n",
    "\n",
    "print(f\"Environment Initialized (0-100). Best Arm Mean: {np.max(TRUE_ARM_MEANS):.2f}\")\n",
    "\n",
    "def get_arm_reward(arm_index):\n",
    "    mean = TRUE_ARM_MEANS[arm_index]\n",
    "    # Scale=5.0 for 0-100 range\n",
    "    reward = np.clip(np.random.normal(loc=mean, scale=5.0), 0.0, 100.0)\n",
    "    return round(reward, 2)\n",
    "\n",
    "def call_mistral(system_prompt, user_prompt):\n",
    "    if MOCK_MODE: return \"MOCK_RESPONSE\"\n",
    "    max_retries = 5\n",
    "    base_wait = 5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.complete(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            if isinstance(content, list):\n",
    "                return \"\".join([c.text for c in content if c.type == 'text']).strip()\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            err = str(e).lower()\n",
    "            wait = base_wait * (2 ** attempt)\n",
    "            print(f\"\\n[API Warning] Attempt {attempt+1} failed: {e}\")\n",
    "            if \"429\" in err or \"rate limit\" in err:\n",
    "                print(f\"Rate Limit Hit. Sleeping {wait}s...\")\n",
    "            else:\n",
    "                print(f\"Retrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "    return \"ERROR\"\n",
    "\n",
    "# --- 4. CLASSES ---\n",
    "class Agent:\n",
    "    def __init__(self, agent_id, total_agents, total_arms, total_rounds):\n",
    "        self.agent_id = f\"Agent_{agent_id}\"\n",
    "        self.total_agents = total_agents\n",
    "        self.total_arms = total_arms\n",
    "        self.total_rounds = total_rounds\n",
    "        self.history = []\n",
    "        self.inbox = []\n",
    "        \n",
    "    def get_system_prompt(self):\n",
    "        return (f\"You are {self.agent_id}, in a {self.total_agents}-agent bandit game. \"\n",
    "                f\"Rewards range from 0 to 100. Goal: Maximize team reward.\")\n",
    "\n",
    "    def _format_history(self):\n",
    "        if not self.history: return \"No history yet.\"\n",
    "        # Returns FULL history\n",
    "        return \"\\n\".join([f\"Round {r['round']}: Pulled Arm {r['arm']}, Reward: {r['payoff']:.2f}\" for r in self.history])\n",
    "\n",
    "    def generate_message(self, current_round, assigned_arms, assignment_map):\n",
    "        hist_str = self._format_history()\n",
    "        user_prompt = (\n",
    "            f\"--- ROUND {current_round} ---\\n\"\n",
    "            f\"My Assigned Arms: {assigned_arms}\\n\"\n",
    "            f\"All Agents' Assignments: {assignment_map}\\n\"\n",
    "            f\"My History:\\n{hist_str}\\n\\n\"\n",
    "            \"Task: Based on history and map, message ONE agent. \"\n",
    "            \"Tell them something useful. Keep the message **short**.\\n\"\n",
    "            \"Format: 'TO: Agent_X | MSG: <content>'\"\n",
    "        )\n",
    "        resp = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        \n",
    "        if MOCK_MODE: return f\"Agent_{random.randint(0, self.total_agents-1)}\", \"Short msg\"\n",
    "        \n",
    "        match = re.search(r\"TO:\\s*(Agent_\\d+).*?MSG:\\s*(.*)\", resp, re.DOTALL | re.IGNORECASE)\n",
    "        if match: return match.group(1).strip(), match.group(2).strip()\n",
    "        return None, None\n",
    "\n",
    "    def receive_message(self, sender, content):\n",
    "        self.inbox.append(f\"From {sender}: {content}\")\n",
    "\n",
    "    def make_choice(self, assigned_arms):\n",
    "        inbox_txt = \"\\n\".join(self.inbox) if self.inbox else \"No messages.\"\n",
    "        user_prompt = (f\"Msgs:\\n{inbox_txt}\\n\\nPick one arm from {assigned_arms}. Return ONLY the integer.\")\n",
    "        resp = call_mistral(self.get_system_prompt(), user_prompt)\n",
    "        \n",
    "        if MOCK_MODE: return random.choice(assigned_arms)\n",
    "        \n",
    "        nums = re.findall(r'\\d+', resp)\n",
    "        if nums:\n",
    "            choice = int(nums[0])\n",
    "            if choice in assigned_arms: return choice\n",
    "        return random.choice(assigned_arms)\n",
    "\n",
    "    def update_history(self, r, arm, payoff):\n",
    "        self.history.append({'round': r, 'arm': arm, 'payoff': payoff})\n",
    "\n",
    "class RLManager:\n",
    "    # FIXED: Arguments now match the call (learning_rate, temperature)\n",
    "    def __init__(self, num_arms, num_agents, learning_rate=0.5, temperature=0.3): \n",
    "        self.num_arms = num_arms\n",
    "        self.num_agents = num_agents\n",
    "        self.lr = learning_rate       # Store internally as self.lr\n",
    "        self.temp = temperature       # Store internally as self.temp\n",
    "        self.weights = np.zeros((num_agents, num_arms))\n",
    "        \n",
    "        # STRICT LIMIT: Forces sharing\n",
    "        self.max_arms_per_agent = 5 \n",
    "\n",
    "    def assign_arms(self):\n",
    "        assignment = {f\"Agent_{i}\": [] for i in range(self.num_agents)}\n",
    "        agent_counts = np.zeros(self.num_agents, dtype=int)\n",
    "        \n",
    "        # 1. Softmax\n",
    "        probs_matrix = softmax(self.weights / self.temp, axis=0)\n",
    "        \n",
    "        # 2. Shuffle Arm Order\n",
    "        arm_order = list(range(self.num_arms))\n",
    "        random.shuffle(arm_order)\n",
    "        \n",
    "        for arm_idx in arm_order:\n",
    "            col_probs = probs_matrix[:, arm_idx].copy()\n",
    "            \n",
    "            # --- THE FIX: MASK FULL AGENTS ---\n",
    "            full_indices = np.where(agent_counts >= self.max_arms_per_agent)[0]\n",
    "            col_probs[full_indices] = 0.0 \n",
    "            \n",
    "            # Re-normalize\n",
    "            total_p = np.sum(col_probs)\n",
    "            if total_p > 0:\n",
    "                col_probs /= total_p\n",
    "                chosen = np.random.choice(self.num_agents, p=col_probs)\n",
    "            else:\n",
    "                # Fallback if everyone is full\n",
    "                avail = [i for i in range(self.num_agents) if agent_counts[i] < self.max_arms_per_agent]\n",
    "                if not avail: avail = list(range(self.num_agents))\n",
    "                chosen = random.choice(avail)\n",
    "\n",
    "            assignment[f\"Agent_{chosen}\"].append(arm_idx)\n",
    "            agent_counts[chosen] += 1\n",
    "        \n",
    "        # Safety Net (Minimal usage now)\n",
    "        empty_agents = [i for i, c in enumerate(agent_counts) if c == 0]\n",
    "        if empty_agents:\n",
    "            donors = [i for i, c in enumerate(agent_counts) if c > 1]\n",
    "            random.shuffle(empty_agents)\n",
    "            for poor in empty_agents:\n",
    "                if not donors: break\n",
    "                rich_guy = donors[0]\n",
    "                steal_idx = random.randint(0, len(assignment[f\"Agent_{rich_guy}\"]) - 1)\n",
    "                arm_val = assignment[f\"Agent_{rich_guy}\"].pop(steal_idx)\n",
    "                agent_counts[rich_guy] -= 1\n",
    "                assignment[f\"Agent_{poor}\"].append(arm_val)\n",
    "                agent_counts[poor] += 1\n",
    "                if agent_counts[rich_guy] <= 1: donors.pop(0)\n",
    "\n",
    "        return assignment\n",
    "\n",
    "    def update_weights(self, agent_id_str, arm_idx, reward):\n",
    "        idx = int(agent_id_str.split(\"_\")[1])\n",
    "        norm_reward = reward / 100.0\n",
    "        self.weights[idx, arm_idx] += self.lr * norm_reward\n",
    "        \n",
    "# --- 5. MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load with Weights Log\n",
    "    start_round, experiment_df, message_log, weights_log = load_checkpoint(N_AGENTS, N_ROUNDS)\n",
    "    \n",
    "    # 2. Setup with RL\n",
    "    agents = [Agent(i, N_AGENTS, N_ARMS, N_ROUNDS) for i in range(N_AGENTS)]\n",
    "    manager = RLManager(N_ARMS, N_AGENTS, learning_rate=RL_LEARNING_RATE, temperature=RL_TEMPERATURE)\n",
    "    \n",
    "    # 3. Restore Agent Memory\n",
    "    if start_round > 0:\n",
    "        print(\"Restoring Memory...\")\n",
    "        for r in range(start_round):\n",
    "            for agent in agents:\n",
    "                rec = experiment_df.at[r, agent.agent_id]\n",
    "                if rec['chosen_arm']:\n",
    "                    agent.update_history(r, rec['chosen_arm'][0], rec['payoff'][0])\n",
    "        \n",
    "        # Restore Manager Weights (Crucial for RL consistency)\n",
    "        if weights_log:\n",
    "            print(\"Restoring Manager Weights...\")\n",
    "            # Set weights to the state at the end of the last completed round\n",
    "            manager.weights = weights_log[-1].copy()\n",
    "            \n",
    "    print(f\"Starting RL Simulation. Alpha={RL_LEARNING_RATE}, Temp={RL_TEMPERATURE}\")\n",
    "    \n",
    "    # 4. Loop\n",
    "    for t in tqdm(range(start_round, N_ROUNDS), desc=\"RL Progress\"):\n",
    "        \n",
    "        assignments = manager.assign_arms()\n",
    "        \n",
    "        # Phase 1: Message\n",
    "        msgs_this_round = []\n",
    "        for agent in agents:\n",
    "            tid, content = agent.generate_message(t, assignments[agent.agent_id], assignments)\n",
    "            if tid and tid in assignments and tid != agent.agent_id:\n",
    "                rec = {'iteration': t, 'sender': agent.agent_id, 'receiver': tid, 'message': content}\n",
    "                msgs_this_round.append(rec)\n",
    "                message_log.append(rec)\n",
    "        \n",
    "        # Deliver\n",
    "        agent_map = {a.agent_id: a for a in agents}\n",
    "        for m in msgs_this_round: agent_map[m['receiver']].receive_message(m['sender'], m['message'])\n",
    "            \n",
    "        # Phase 2: Action\n",
    "        round_payoffs = []\n",
    "        for agent in agents:\n",
    "            my_arms = assignments[agent.agent_id]\n",
    "            choice = agent.make_choice(my_arms)\n",
    "            payoff = get_arm_reward(choice)\n",
    "            \n",
    "            agent.update_history(t, choice, payoff)\n",
    "            \n",
    "            # Update Manager\n",
    "            manager.update_weights(agent.agent_id, choice, payoff)\n",
    "            \n",
    "            experiment_df.at[t, agent.agent_id] = {\n",
    "                'assigned_arms': list(my_arms),\n",
    "                'chosen_arm': [choice],\n",
    "                'payoff': [payoff]\n",
    "            }\n",
    "            round_payoffs.append(payoff)\n",
    "            \n",
    "        # Stats\n",
    "        experiment_df.at[t, 'Total_Payoff'] = np.average(round_payoffs)\n",
    "        \n",
    "        # SNAPSHOT THE MATRIX\n",
    "        weights_log.append(manager.weights.copy())\n",
    "        \n",
    "        # Atomic Save\n",
    "        save_checkpoint(experiment_df, message_log, weights_log)\n",
    "        \n",
    "    print(\"Done! Exporting...\")\n",
    "    experiment_df.to_csv(\"final_rl_results.csv\")\n",
    "    pd.DataFrame(message_log).to_csv(\"final_rl_messages.csv\")\n",
    "    \n",
    "    # Save final weights history for visualization\n",
    "    with open(\"final_weights_history.pkl\", \"wb\") as f:\n",
    "        pickle.dump(weights_log, f)\n",
    "        \n",
    "    print(\"All files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLManager:\n",
    "    def __init__(self, num_arms, num_agents, lr=0.5, temp=0.3): # <--- LOWER TEMP (was 2.0)\n",
    "        self.num_arms = num_arms\n",
    "        self.num_agents = num_agents\n",
    "        self.lr = lr\n",
    "        self.temp = temp\n",
    "        self.weights = np.zeros((num_agents, num_arms))\n",
    "        \n",
    "        # Calculate strict capacity limits to force distribution\n",
    "        # If we have 50 arms and 30 agents, avg is 1.6 arms/agent.\n",
    "        # We allow a buffer. Max = 5 ensures no one gets overwhelmed.\n",
    "        self.max_arms_per_agent = 5 \n",
    "\n",
    "    def assign_arms(self):\n",
    "        assignment = {f\"Agent_{i}\": [] for i in range(self.num_agents)}\n",
    "        \n",
    "        # Track how many arms each agent currently has\n",
    "        agent_counts = np.zeros(self.num_agents, dtype=int)\n",
    "        \n",
    "        # 1. Create Probability Matrix (Softmax)\n",
    "        # We add a tiny epsilon to avoid division by zero errors later\n",
    "        probs_matrix = softmax(self.weights / self.temp, axis=0)\n",
    "        \n",
    "        # 2. Shuffle Arms (Assign in random order so arm #0 isn't always first)\n",
    "        arm_order = list(range(self.num_arms))\n",
    "        random.shuffle(arm_order)\n",
    "        \n",
    "        for arm_idx in arm_order:\n",
    "            # Get probs for this arm across all agents\n",
    "            col_probs = probs_matrix[:, arm_idx].copy()\n",
    "            \n",
    "            # --- CONSTRAINT: MASK FULL AGENTS ---\n",
    "            # Identify agents who hit the cap\n",
    "            full_agents_indices = np.where(agent_counts >= self.max_arms_per_agent)[0]\n",
    "            \n",
    "            # Set their prob to 0\n",
    "            col_probs[full_agents_indices] = 0.0\n",
    "            \n",
    "            # Renormalize so probabilities sum to 1 again\n",
    "            total_p = np.sum(col_probs)\n",
    "            \n",
    "            if total_p > 0:\n",
    "                col_probs /= total_p\n",
    "                # Sample an agent\n",
    "                chosen_agent = np.random.choice(self.num_agents, p=col_probs)\n",
    "            else:\n",
    "                # Edge Case: Everyone is full (shouldn't happen if math works)\n",
    "                # or numeric instability. Fallback to random non-full agent.\n",
    "                available = [i for i in range(self.num_agents) if agent_counts[i] < self.max_arms_per_agent]\n",
    "                if not available: \n",
    "                    # If truly everyone is full (e.g. N_ARMS > N_AGENTS * MAX), pick random\n",
    "                    available = list(range(self.num_agents))\n",
    "                chosen_agent = random.choice(available)\n",
    "\n",
    "            # Assign\n",
    "            assignment[f\"Agent_{chosen_agent}\"].append(arm_idx)\n",
    "            agent_counts[chosen_agent] += 1\n",
    "        \n",
    "        # 3. Safety Net (Much lighter now)\n",
    "        # Since we enforced a Max Cap, the arms naturally spread out.\n",
    "        # But we still check for empty agents just in case N_ARMS is small.\n",
    "        empty_agents = [i for i, c in enumerate(agent_counts) if c == 0]\n",
    "        \n",
    "        if empty_agents:\n",
    "            # Identify agents who have > 1 arm (can afford to give one up)\n",
    "            donors = [i for i, c in enumerate(agent_counts) if c > 1]\n",
    "            random.shuffle(empty_agents)\n",
    "            \n",
    "            for poor in empty_agents:\n",
    "                if not donors: break\n",
    "                \n",
    "                # Find a donor\n",
    "                rich_guy = donors[0]\n",
    "                \n",
    "                # Pick a random arm to steal (not necessarily the last one)\n",
    "                steal_idx = random.randint(0, len(assignment[f\"Agent_{rich_guy}\"]) - 1)\n",
    "                arm_val = assignment[f\"Agent_{rich_guy}\"].pop(steal_idx)\n",
    "                agent_counts[rich_guy] -= 1\n",
    "                \n",
    "                # Give to poor\n",
    "                assignment[f\"Agent_{poor}\"].append(arm_val)\n",
    "                agent_counts[poor] += 1\n",
    "                \n",
    "                if agent_counts[rich_guy] <= 1:\n",
    "                    donors.pop(0)\n",
    "\n",
    "        return assignment\n",
    "\n",
    "    def update_weights(self, agent_id_str, arm_idx, reward):\n",
    "        idx = int(agent_id_str.split(\"_\")[1])\n",
    "        norm_reward = reward / 100.0\n",
    "        self.weights[idx, arm_idx] += self.lr * norm_reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
